# Do not use this configuration in production.
# It is for demonstration purposes only.

server:
  http_listen_port: 3200
  grpc_listen_port: 9097
  log_level: info

query_frontend:
  search:
    duration_slo: 5s
    throughput_bytes_slo: 1.073741824e+09
    metadata_slo:
      duration_slo: 5s
      throughput_bytes_slo: 1.073741824e+09
  trace_by_id:
    duration_slo: 100ms
  metrics:
    max_duration: 120h # maximum duration of a metrics query, increase for local setups
    query_backend_after: 5m
    duration_slo: 5s
    throughput_bytes_slo: 1.073741824e+09

distributor:
  receivers: # this configuration will listen on all ports and protocols that tempo is capable of.
    otlp:
      protocols:
        grpc:
          endpoint: "tempo:4317"
        http:
          endpoint: "tempo:4318"

ingester:
  concurrent_flushes: 4
  flush_check_period: 10s
  flush_op_timeout: 5m0s
  trace_idle_period: 10s
  max_block_duration: 5m
  max_block_bytes: 524_288_000
  complete_block_timeout: 15m0s
  override_ring_key: ring
  flush_all_on_shutdown: true

compactor:
  compaction:
    compaction_window: 1h # blocks in this time window will be compacted together
    max_block_bytes: 100_000_000 # maximum size of compacted blocks
    block_retention: 1h
    compacted_block_retention: 10m

metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: podman
  storage:
    path: /tmp/tempo/generator/wal
    remote_write:
      - url: http://localhost:9009/api/v1/write
        send_exemplars: true
  traces_storage:
    path: /tmp/tempo/generator/traces
  processor:
    local_blocks:
      filter_server_spans: false
      flush_to_storage: true

storage:
  trace:
    backend: local # backend configuration to use
    local:
      path: /tmp/tempo/blocks
    wal:
      path: /tmp/tempo/wal
    block:
      bloom_filter_false_positive: .05 # bloom filter false positive rate.  lower values create larger filters but fewer false positives
    pool:
      max_workers: 100 # worker pool determines the number of parallel requests to the object store backend
      queue_depth: 10000

overrides:
  defaults:
    metrics_generator:
      processors: [service-graphs, span-metrics, local-blocks] # enables metrics generator
      generate_native_histograms: both
